\chapter{Thesis Plan}
\section{Definition of Success}\label{sec:success}
In order to develop a system that adequately addresses the gaps in knowledge identified in Chapter \ref{chap:litReview}, some method of classifying the performance of a system must be determined. These classification will serve as goals that will significantly shape the creation of the system so ensuring accurate and reasonable specification is extremely important.

The two main tenets of any aggregation platform are validity and reliability; in this case validity take the form of financial performance and reliability will be the system's robustness against various factors that have the potential to compromise validity. Further, it is likely worth examining the performance of the algorithm on a portfolio level and an individual stock level independently, in order to allow for better speculation on potential for generalisation. Full reasoning and explanation for the success classifications follow, however an summarised form is outlined in table \ref{tab:success}.

\subsection{Portfolio Performance}
The ideal algorithm would be able to isolate both positive and negative alpha within analytical firm and assign trust based on this. As such, once alpha is properly identified this ideal system should be able to generate returns in excess of the portfolio on which is it trained. The SP100, SP400 and SP600 are portfolios of large, medium, and small market cap stocks respectively and will be used to assess the system as they collectively provide a good proxy for most regularly traded stocks, have large volumes of recommendation and historical price data, and will allow for an assessment of the correlation (if any) between efficacy of the algorithm and market capitalisation.

\subsection{Individual Performance}
The most typical use case for a stock recommendation is to aide in determining the most appropriate action to take regarding a single stock, thus an algorithm that can supplement this data by assessing analysts over a wider portfolio and then augmenting and aggregating recommendations based on this exogenous information would provide enhance their usability.  

\subsection{Robustness}
Many research houses are part of a larger corporate structure that may include prop trading divisions so there can be a direct relationship between the price of a security and the overall profit or loss of the entire firm. This can create an incentive for cheating as recommendations are able to influence stock prices. Such cheating is likely to be systematic rather than one-off and should thus should be punished by the system, however the uncontrolled environment that the algorithm will be used in is not suitable for objectively assessing specific forms of it. 

\begin{table}[p]
    \centering
    \begin{tabularx}{0.95\textwidth}{@{\extracolsep{\fill}}cXXX}
        \toprule\toprule
         & Aggregate Level of Financial Success  &Individual Level of Financial Success & Robustness of System \\\midrule
        Ideal & System outperforms SP[1$|$4$|$6]00 & More accurate than lagged Fama-French model for an individual security & Proven against experimental data to be highly robust against collusion and spam\\
        \addlinespace
        Good & Outperforms simple average of Recommendations & More Accurate than a CAPM model for an individual security & Robust against collusion and span in all but the most extreme cases\\
        \addlinespace
        Acceptable & System provides greater returns than inflation && Performs better than simple average against white noise and some collusion \\ \bottomrule
    \end{tabularx}
    \caption{Classifications of success}
    \label{tab:success}
\end{table}


\section{Schedule}
The first stage of the thesis includes all preparation work and production of the initial algorithm. The first part of this stage primarily involved gaining a deeper understanding of the topic and greater intuition about the topic so that any relevant gaps in the literature could be adequately captured and addressed by the problem statement. Once this was complete the process of cleaning data and formatting it as seen in tables \ref{tab:histPrice}, \ref{tab:industries}, and \ref{tab:recommendations}. This was done for the SP100, SP400, and SP600 for reasons explained in \ref{sec:plan}. 

After the problem had been formulated and the data was in a form that was mostly ideal, preliminary work began on several aggregation methods. Details on several on the approaches are laid out in section \ref{sec:plan} and the bulk of this work will occur over the holiday period and early next term as illustrated in figure \ref{fig:gantt}.

The second stage will start at the beginning of term 2 and overlap slightly with stage one as some fine tuning is naturally a part of the development process. Towards the end and after the fine tuning is complete, the single best performing algorithm will be selected. This process will also overlap with fine tuning to ensure that the best version of the best algorithm is chosen.

Concurrently with stage two, in stage three simulated data will be created that will aid in the assessment of the chosen program's robustness against collusion and white noise. After this is complete and the optimum program has been chosen in stage two then the program will be assessed based on the definition of success outlined in section \ref{sec:success}.

Stage four will take place over the entirety term 3 and the holiday preceding it. This will involve the automating the process of data requests and generalising the algorithm so that is can use trustworthiness scores calculated for all analysts to produce recommendations for either a single stock or a portfolio. This platform would likely be online however ideally it would have an API so that it could be integrated into trading platforms such as nabtrade, CommSec, or Robinhood.
{
\newgeometry{left=1.5cm, bottom =1.5cm, top=1.5cm, right=1.5cm}
\begin{landscape}
\pagestyle{empty}

\begin{scriptsize}
\begin{figure}[p]
\begin{center}
\begin{ganttchart}[
hgrid,
vgrid]{2}{41}
%labels
\gantttitle{Term 1}{10}
\gantttitle{}{5}
\gantttitle{Term 2}{10}
\gantttitle{}{5}
\gantttitle{Term 3}{10}\\
\gantttitlelist{1,...,40}{1}\\
\gantttitlelist{1,...,10}{1}
\gantttitle{}{5}

\gantttitlelist{1,...,10}{1}
\gantttitle{}{5}

\gantttitlelist{1,...,10}{1}\\
%tasks
\ganttgroup[inline=false]{Stage 1}{2}{18}\\
\ganttbar{Literature Survey}{2}{6} \\
\ganttbar{Problem Formulation}{3}{6} \\
\ganttbar{Cleaning Data}{4}{8} \\
\ganttbar{Prelim. System Design}{8}{18} \\
\ganttgroup[inline=false]{Stage 2}{17}{23}\\
\ganttbar{Fine Tuning}{17}{21} \\
\ganttbar{Choose Best}{20}{23} \\
\ganttgroup[inline=false]{Stage 3}{21}{25}\\
\ganttbar{Create Dummy Data}{21}{22}\\
\ganttbar{Assess Performance}{22}{25} \\
\ganttgroup[inline=false]{Stage 4}{27}{40}\\
\ganttbar{Web Platform}{27}{40}


\end{ganttchart}
\end{center}
\caption{Gantt Chart}
\label{fig:gantt}
\end{figure}
\end{scriptsize}

\restoregeometry
\pagestyle{plain}
\end{landscape}

}
\section{Proposed Approaches}\label{sec:plan}



